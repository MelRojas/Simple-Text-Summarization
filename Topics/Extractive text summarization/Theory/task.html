<div class="step-text">
<p>In this topic, we will take a look at a historical approach to automatic text summarization, extractive summarization, which selects a subset of sentences from the original document based on the importance metrics. Those importance scores determine whether a particular sentence will be included in the final summary.</p><h5 id="a-note-on-the-intermediate-text-representation">A note on the intermediate text representation</h5><p>Extractive summarization creates an intermediate representation of the text to find the important content. There are two types of representation: <strong>topic representation</strong> and <strong>indicator representation:</strong></p><p style="text-align: center;"><picture><img alt="A comparative graph for intermediate representation" height="392" src="https://ucarecdn.com/fca561f3-f314-4981-8342-8e71c7b784ea/" width="800"/></picture></p><p>The topic-words technique identifies the words that describe the document's topic. One of the earliest works on summarization by H.P. Luhn used frequency thresholds to find the words that are representative of the topic. Latent semantic analysis (LSA) is an unsupervised method for extracting a representation of text based on observed words. With frequency-driven approaches, the word's weights (binary or continious) determine the word's correlation to the topic. Bayesian topic models are probabilistic models (e.g., HIERSUM) which use Latent Dirichlet Allocation (LDA). The main idea behind LDA is that documents are represented as a mixture of topics, where each topic is a probability distribution over words.</p><p>In the indicator representation, the sentence is represented as a list of features such as sentence length or relative position of the sentence. Graph methods (e.g., TextRank) represent the documents as a connected graph, with sentences as the vertices of the graph and edges between the sentences as the indicators of sentence similarity. ML approaches (e.g. Naive Bayes), classify the sentences as summary or non-summary based on their features, given a training set of documents and their extractive summaries.<br/></p><h5 id="the-preliminary-steps">The preliminary steps</h5><p>There are roughly three stages in the process of extractive summarization:</p><ol><li><p>Generating an intermediate text representation;</p></li><li><p>Assigning an importance score to every sentence;</p></li><li><p>Selecting the most important sentences to produce the summary.</p></li></ol><p>We will track the described stages through three solutions — a technique based on word frequency, Luhn's summarizer, TextRank, a graph-based method, and the application of LSA.</p><p>We will use the <a href="https://huggingface.co/datasets/cnn_dailymail" rel="noopener noreferrer nofollow" target="_blank">Daily Mail/CNN news article dataset</a> by HuggingFace.</p><p>Here are the required packages:</p><pre><code class="language-python">pip install spacy numpy nltk sumy rouge datasets</code></pre><p>We will use the <a href="https://github.com/miso-belica/sumy" rel="noopener noreferrer nofollow" target="_blank">Sumy</a> package, the most complete and maintained library for extractive summarization.</p><p>Import the necessary packages:</p><pre><code class="language-python">import datasets
import numpy as np
from rouge import Rouge</code></pre><p>Load the <code class="language-python">CNN</code> dataset (it may take some time):</p><pre><code class="language-python">dataset = datasets.load_dataset("cnn_dailymail", '3.0.0')</code></pre><p> Let's take a look at the structure of the first dictionary in the train section of the dataset:</p><pre><code class="language-python">first_entry = dataset['train'][0]</code></pre><p> The articles are stored with the <code class="language-python">article</code> key, provided summaries — with the <code class="language-python">highlights</code> key.</p><p>A small utility function to obtain the scores that will be reused later:</p><pre><code class="language-python">def evaluate_summary(prediction: str, reference: str) -&gt; str:
    rouge = Rouge()
    scores = rouge.get_scores(prediction, reference)[0]
    out = {k: round(v["f"], 2) for k, v in scores.items()}
    avg = round(np.mean(list(out.values())), 2)
    return (
        f"ROUGE1: {out['rouge-1']} | ROUGE2: {out['rouge-2']}"
        f"| ROUGE_L: {out['rouge-l']} | AVG: {avg}"
    )</code></pre><h5 id="luhns-summarizer">Luhn's summarizer</h5><p>Luhn's summarizer was one of the first attempts in the field of text summarization. In the 1958 paper ''The Automatic Creation of Literature Abstracts", Luhn proposes that word frequency determines the word's significance. The diagram below gives the conceptual overview of the Luhn's approach:</p><p style="text-align: center;"><picture><img alt="The Luhn's summarizer flowchart" height="1046" src="https://ucarecdn.com/729315a6-aaa7-4855-be32-a9afee05b670/" width="500"/></picture></p><p>Let's see how Luhn's summarizer is implemented in Sumy. Import the required packages:</p><ul><li><p></p></li></ul><pre><code class="language-python">from sumy.nlp.tokenizers import Tokenizer
from sumy.nlp.stemmers import Stemmer
from sumy.parsers.plaintext import PlaintextParser
from sumy.utils import get_stop_words
from sumy.summarizers.luhn import LuhnSummarizer
import nltk
nltk.download('punkt')</code></pre><p>Usage of <code class="language-python">LuhnSummarizer</code> is pretty straightforward:</p><pre><code class="language-python">def summarize_luhn(article: str, sentence_count: int) -&gt; str:
    ''' Utility function to perform Luhn's summarization.

        By default, LuhnSummarizer will select 100% of non-stop post-processed words as
        significant, but you can overwrite the significant_percantage attribute as a 
        fraction: summarizerLuhn.significant_percentage = 1/3

    '''
        
    parser = PlaintextParser.from_string(article, Tokenizer('english'))
    summarizerLuhn = LuhnSummarizer(Stemmer('english'))
    summarizerLuhn.stop_words = get_stop_words('english')
    luhn_summary = summarizerLuhn(parser.document, sentences_count = sentence_count)
    return ' '.join([str(sentence) for sentence in luhn_summary])


summarize_luhn(first_entry['article'], sentence_count = 2)</code></pre><p>We get the <code class="language-python">ROUGE</code> scores:</p><pre><code class="language-no-highlight">ROUGE1: 0.43 | ROUGE2: 0.32 | ROUGE_L: 0.43 | AVG: 0.39</code></pre><p>This means that 43% of unigrams (<code class="language-python">ROUGE-1</code>) and 32% of bigrams (<code class="language-python">ROUGE-2</code>) match in the golden and produced summary, while the longest common subsequences (<code class="language-python">ROUGE-L</code>) match by 43%, with an average of 39% match.</p><p>Here is the visualization of the matching words of both summaries:</p><p><picture><source media="(max-width: 480px)" srcset="https://ucarecdn.com/4c9d0e37-6654-403a-9e35-c38d095fc45e/-/stretch/off/-/resize/480x/-/format/webp/ 1x,https://ucarecdn.com/4c9d0e37-6654-403a-9e35-c38d095fc45e/-/stretch/off/-/resize/960x/-/format/webp/ 2x,https://ucarecdn.com/4c9d0e37-6654-403a-9e35-c38d095fc45e/-/stretch/off/-/resize/1440x/-/format/webp/ 3x" type="image/webp"/><source media="(max-width: 800px)" srcset="https://ucarecdn.com/4c9d0e37-6654-403a-9e35-c38d095fc45e/-/stretch/off/-/resize/800x/-/format/webp/ 1x,https://ucarecdn.com/4c9d0e37-6654-403a-9e35-c38d095fc45e/-/stretch/off/-/resize/1600x/-/format/webp/ 2x,https://ucarecdn.com/4c9d0e37-6654-403a-9e35-c38d095fc45e/-/stretch/off/-/resize/2400x/-/format/webp/ 3x" type="image/webp"/><source srcset="https://ucarecdn.com/4c9d0e37-6654-403a-9e35-c38d095fc45e/-/stretch/off/-/resize/1100x/-/format/webp/ 1x,https://ucarecdn.com/4c9d0e37-6654-403a-9e35-c38d095fc45e/-/stretch/off/-/resize/2200x/-/format/webp/ 2x,https://ucarecdn.com/4c9d0e37-6654-403a-9e35-c38d095fc45e/-/stretch/off/-/resize/3000x/-/format/webp/ 3x" type="image/webp"/><img alt="Highlighted matches between the Golden and the Predicted summaries using Luhn's summarizer" height="151" src="https://ucarecdn.com/4c9d0e37-6654-403a-9e35-c38d095fc45e/" width="1261"/></picture></p><p>Luhn's algorithm is intuitive in implementation and unsupervised but is known to have limited accuracy, a lack of synonym detection, and is prone to redundancy.</p><h5 id="textrank">TextRank</h5><p>TextRank represents the document as a graph with sentences as nodes and sentence content overlapping as edges. All edges of the graph are assigned random weights upon initialization, then the weight is determined by a similarity measure.</p><p>Given two sentences <span class="math-tex">\(S_i = \{ w_{i_1}, w_{i_2}, w_{i_3} ... w_{i_n} \}\)</span>, where <span class="math-tex">\(\{ w_{i_1}, w_{i_2}, w_{i_3} ... w_{i_n} \}\)</span> is a set of <span class="math-tex">\(n\)</span> words in the sentence <span class="math-tex">\(i\)</span>, and <span class="math-tex">\(S_j = \{ w_{j_1}, w_{j_2}, w_{j_3} ... w_{j_y} \}\)</span> is a set of <span class="math-tex">\(y\)</span> words in the sentence <span class="math-tex">\(j\)</span>. <span class="math-tex">\(|S_i|\)</span>, <span class="math-tex">\(|S_j|\)</span> — lengths of respective sentences. Then, the similarity function for sentences can be introduced as follows:</p><p><span class="math-tex">\(\text{Sim}(S_i, S_j) = \frac{|{\{ w_k} \vert {w_k} \in S_i \&amp; w_k \in S_j \}|}{\log(|S_i|) + \log(|S_j|)}\)</span>The node's rank <strong>(weight)</strong> can be calculated as:</p><p><span class="math-tex">\(\text{WS}(V_i) = (1 - d) + d* \sum_{V_j \in \text{In}(V_i)} \frac{w_{ij}}{\sum_{V_k \in \text{Out}(V_j)} w_{jk}}\text{WS}(V_j)\)</span></p><p>Where</p><ul><li><p><span class="math-tex">\(d\)</span> — a damping factor, a probability of jumping from a node to a connected node in the graph <span class="math-tex">\(d∈[0,1]\)</span>, both TextRank and PageRank have <span class="math-tex">\(d = 0.85\)</span>, with <span class="math-tex">\(1-d\)</span> being a probability of jumping to a random node;</p></li><li><p><span class="math-tex">\(V_i\)</span>, <span class="math-tex">\(V_j\)</span> — two connected nodes;</p></li><li><p><span class="math-tex">\(w_{ij}\)</span> — a previously calculated sentence similarity score for sentences <span class="math-tex">\(i,j\)</span>;</p></li><li><p><span class="math-tex">\(\text{In}(V_i)\)</span> — a set of nodes that point to <span class="math-tex">\(V_i\)</span>;</p></li><li><p> <span class="math-tex">\(\text{Out}(V_j)\)</span> — a set of nodes that point to <span class="math-tex">\(V_j\)</span> </p></li></ul><p>This formula is applied recursively until a stable score is assigned to a node. The score becomes stable when the error rate for the node's score is smaller than a specified threshold, where the <strong>error rate</strong> is <span class="math-tex">\(S^{k+1}(V_i) - S^{k}(V_i)\)</span>, with <span class="math-tex">\(S^{k+1}(V_i)\)</span>, <span class="math-tex">\(S^k(V_i)\)</span> — sentence scores obtained at <span class="math-tex">\(k+1\text{'th}\)</span> and <span class="math-tex">\(k\text{'th}\)</span> iteration respectively.</p><p style="text-align: center;"><picture><img alt="The TextRank flowchart" height="908" src="https://ucarecdn.com/103c7e98-827f-4d47-bc42-9c3370926544/" width="500"/></picture></p><p>After getting a grasp on TextRank, let's review the code implementation using the <code class="language-python">sumy</code> library. </p><pre><code class="language-python"># ... previously imported packages
from sumy.summarizers.text_rank import TextRankSummarizer

def summarize_textrank(article: str, sentence_count: int) -&gt; str: 
    parser = PlaintextParser.from_string(article, Tokenizer('english'))
    summarizerTR = TextRankSummarizer(Stemmer('english'))
    summarizerTR.stop_words = get_stop_words('english')
    textrank_summary = summarizerTR(parser.document, sentences_count = sentence_count)
    return ' '.join([str(sentence) for sentence in textrank_summary])


summarize_textrank(first_entry['article'], sentence_count = 2)</code></pre><p>With the following <code class="language-python">ROUGE</code> scores:</p><pre><code class="language-no-highlight">ROUGE1: 0.43 | ROUGE2: 0.32| ROUGE_L: 0.43 | AVG: 0.39</code></pre><p>Once again, observe the highlighted words from both summaries:</p><p><picture><source media="(max-width: 480px)" srcset="https://ucarecdn.com/be7e8eea-5d2c-454f-a9c3-a1539628cb53/-/stretch/off/-/resize/480x/-/format/webp/ 1x,https://ucarecdn.com/be7e8eea-5d2c-454f-a9c3-a1539628cb53/-/stretch/off/-/resize/960x/-/format/webp/ 2x,https://ucarecdn.com/be7e8eea-5d2c-454f-a9c3-a1539628cb53/-/stretch/off/-/resize/1440x/-/format/webp/ 3x" type="image/webp"/><source media="(max-width: 800px)" srcset="https://ucarecdn.com/be7e8eea-5d2c-454f-a9c3-a1539628cb53/-/stretch/off/-/resize/800x/-/format/webp/ 1x,https://ucarecdn.com/be7e8eea-5d2c-454f-a9c3-a1539628cb53/-/stretch/off/-/resize/1600x/-/format/webp/ 2x,https://ucarecdn.com/be7e8eea-5d2c-454f-a9c3-a1539628cb53/-/stretch/off/-/resize/2400x/-/format/webp/ 3x" type="image/webp"/><source srcset="https://ucarecdn.com/be7e8eea-5d2c-454f-a9c3-a1539628cb53/-/stretch/off/-/resize/1100x/-/format/webp/ 1x,https://ucarecdn.com/be7e8eea-5d2c-454f-a9c3-a1539628cb53/-/stretch/off/-/resize/2200x/-/format/webp/ 2x,https://ucarecdn.com/be7e8eea-5d2c-454f-a9c3-a1539628cb53/-/stretch/off/-/resize/3000x/-/format/webp/ 3x" type="image/webp"/><img alt="Highlighted matches between the Golden and the Predicted summaries using TextRank" height="151" src="https://ucarecdn.com/be7e8eea-5d2c-454f-a9c3-a1539628cb53/" width="1261"/></picture></p><p>The main advantage of the TextRank algorithm is that it is unsupervised and does not require a training corpus, also you can use it with texts in any language. The drawback lies in the lack of semantic similarity detection — certain words may be important in the context, but won't be detected because TextRank doesn't differentiate synonyms. Furthermore, the results depend on the choice of the sentence similarity function.</p><h5 id="latent-semantic-analysis-application-to-auto-summarization">Latent semantic analysis application to auto-summarization</h5><p>The third algorithm utilizes latent semantic analysis, a multipurpose natural language processing technique. A document is represented as a matrix, and singular value decomposition is performed to extract the underlying relations between the document and the present terms.</p><p>At first, we select unique words from the entire document. Then, the algorithm constructs the matrix <span class="math-tex">\(A_{m×n}\)</span>, where <span class="math-tex">\(m\)</span> is the number of unique words, <span class="math-tex">\(n\)</span> is the number of sentences, while <span class="math-tex">\(w_{i,j}\)</span> shows the importance of a word <span class="math-tex">\(i\)</span> in the sentence <span class="math-tex">\(j\)</span>. Each column of <span class="math-tex">\(A\)</span> is a sentence, and rows represent the importance measure for each unique word in relation to the sentence. The original algorithm uses the weighted term-frequency as the word's importance measure. <span class="math-tex">\(A\)</span> will be sparse since every sentence doesn't contain every single word of the document.</p><p style="text-align: center;"><picture><source media="(max-width: 480px)" srcset="https://ucarecdn.com/f9dc8135-d82c-4f67-8011-a55baa30c400/-/stretch/off/-/resize/480x/-/format/webp/ 1x,https://ucarecdn.com/f9dc8135-d82c-4f67-8011-a55baa30c400/-/stretch/off/-/resize/960x/-/format/webp/ 2x,https://ucarecdn.com/f9dc8135-d82c-4f67-8011-a55baa30c400/-/stretch/off/-/resize/1440x/-/format/webp/ 3x" type="image/webp"/><source media="(max-width: 800px)" srcset="https://ucarecdn.com/f9dc8135-d82c-4f67-8011-a55baa30c400/-/stretch/off/-/resize/800x/-/format/webp/ 1x,https://ucarecdn.com/f9dc8135-d82c-4f67-8011-a55baa30c400/-/stretch/off/-/resize/1600x/-/format/webp/ 2x,https://ucarecdn.com/f9dc8135-d82c-4f67-8011-a55baa30c400/-/stretch/off/-/resize/2400x/-/format/webp/ 3x" type="image/webp"/><source srcset="https://ucarecdn.com/f9dc8135-d82c-4f67-8011-a55baa30c400/-/stretch/off/-/resize/1100x/-/format/webp/ 1x,https://ucarecdn.com/f9dc8135-d82c-4f67-8011-a55baa30c400/-/stretch/off/-/resize/2200x/-/format/webp/ 2x,https://ucarecdn.com/f9dc8135-d82c-4f67-8011-a55baa30c400/-/stretch/off/-/resize/3000x/-/format/webp/ 3x" type="image/webp"/><img alt="The matrix A, where columns represent n sentences and rows represent m words from the document" height="284" src="https://ucarecdn.com/f9dc8135-d82c-4f67-8011-a55baa30c400/" width="650"/></picture></p><p>In the next step, the singular value decomposition is performed on <span class="math-tex">\(A\)</span>:</p><p style="text-align: center;"><span class="math-tex">\(A=UΣV^T\)</span>,</p><p><span class="math-tex">\(U_{m×n}\)</span> contains the row vectors <span class="math-tex">\(ϕ_j=[u_{j1}u_{j2}...u_{jr}]\)</span>, <span class="math-tex">\(j\)</span> is a row in the matrix <span class="math-tex">\(A\)</span>, and <span class="math-tex">\(r\)</span> - singular vector space dimensionality; <span class="math-tex">\(\Sigma_{n \times n}\)</span> — diagonal matrix with values sorted in descending order, and <span class="math-tex">\(V_{n \times n}^T\)</span>, where each sentence <span class="math-tex">\(i\)</span> is represented by the column vector <span class="math-tex">\(ψ_i=[v_{i1}v_{i2}...v_{ir}]^T\)</span>. </p><p>SVD creates a mapping between the words-by-sentences matrix <span class="math-tex">\(A\)</span> and the extracted concepts in the singular vector space. The concept can be thought of as a pattern of words or phrases that appear in similar contexts, for example, the words 'car' and 'bus' will fall under the concept of vehicle. <span class="math-tex">\(V^T\)</span> is row-sorted in descending order by the importance of a concept extracted from the sentence and used in the sentence selection, with cells representing the relation between the concepts and the sentences. In the original implementation, the sentences are chosen from the most significant extracted concepts until the resulting summary contains a pre-defined number of sentences.</p><p style="text-align: center;"><picture><img alt="LSA flowchart" height="511" src="https://ucarecdn.com/aa5e97d0-c8b4-436d-a56a-f57a5cc94c27/" width="600"/></picture></p><p>Let's dive into the implementation:</p><pre><code class="language-python"># ... previously imported packages
from sumy.summarizers.lsa import LsaSummarizer

def summarize_lsa(article: str, sentence_count: int) -&gt; str:
    parser = PlaintextParser.from_string(article, Tokenizer('english'))
    summarizerLSA = LsaSummarizer(Stemmer('english'))
    summarizerLSA.stop_words = get_stop_words('english')
    lsa_summary = summarizerLSA(parser.document, sentences_count = sentence_count)
    return ' '.join([str(sentence) for sentence in lsa_summary])


summarize_lsa(first_entry['article'], sentence_count = 2)</code></pre><p>The evaluation results:</p><pre><code class="language-python">ROUGE1: 0.12 | ROUGE2: 0.0 | ROUGE_L: 0.12 | AVG: 0.08</code></pre><p> Looking at the summary word match, we can see why such low scores are obtained:</p><p><picture><source media="(max-width: 480px)" srcset="https://ucarecdn.com/e0ab6617-3f3a-49b1-b42c-d3c4b390fc15/-/stretch/off/-/resize/480x/-/format/webp/ 1x,https://ucarecdn.com/e0ab6617-3f3a-49b1-b42c-d3c4b390fc15/-/stretch/off/-/resize/960x/-/format/webp/ 2x,https://ucarecdn.com/e0ab6617-3f3a-49b1-b42c-d3c4b390fc15/-/stretch/off/-/resize/1440x/-/format/webp/ 3x" type="image/webp"/><source media="(max-width: 800px)" srcset="https://ucarecdn.com/e0ab6617-3f3a-49b1-b42c-d3c4b390fc15/-/stretch/off/-/resize/800x/-/format/webp/ 1x,https://ucarecdn.com/e0ab6617-3f3a-49b1-b42c-d3c4b390fc15/-/stretch/off/-/resize/1600x/-/format/webp/ 2x,https://ucarecdn.com/e0ab6617-3f3a-49b1-b42c-d3c4b390fc15/-/stretch/off/-/resize/2400x/-/format/webp/ 3x" type="image/webp"/><source srcset="https://ucarecdn.com/e0ab6617-3f3a-49b1-b42c-d3c4b390fc15/-/stretch/off/-/resize/1100x/-/format/webp/ 1x,https://ucarecdn.com/e0ab6617-3f3a-49b1-b42c-d3c4b390fc15/-/stretch/off/-/resize/2200x/-/format/webp/ 2x,https://ucarecdn.com/e0ab6617-3f3a-49b1-b42c-d3c4b390fc15/-/stretch/off/-/resize/3000x/-/format/webp/ 3x" type="image/webp"/><img alt="Highlighted matches between the Golden and the Predicted summaries using LSA" height="151" src="https://ucarecdn.com/e0ab6617-3f3a-49b1-b42c-d3c4b390fc15/" width="1261"/></picture></p><p>LSA's application comes with several limitations. If the size of the input document is large enough, it leads to degrading performance due to the SVD calculation. Plus, the results are difficult to interpret. This approach, however limited it may be, has the ability to detect synonyms and polysemous words (containing multiple meanings).</p><h5 id="conclusion">Conclusion </h5><p>In this topic, we've reviewed a few fundamental solutions in extractive text summarization. All the described approaches have the advantage of being language-independent and unsupervised, but each method has its limitations discussed in later research. Once again:</p><ul><li><p>The Luhn's algorithm is simple to implement but has limited accuracy, lack of synonym detection, and is prone to redundancy;</p></li><li><p>The TextRank algorithm does not require a training corpus; you can use it with texts in any language. However, it lacks semantic similarity detection;</p></li><li><p>The LSA may be slow due to SVD calculation, and the results are difficult to interpret. The big plus is that it can detect synonyms and polysemous words.</p></li></ul><p>You can find more on this topic in <a href="https://hyperskill.org/blog/post/mastering-stemming-and-lemmatization" rel="noopener noreferrer nofollow" target="_blank">Mastering Stemming and Lemmatization</a> on Hyperskill Blog.</p>
</div>